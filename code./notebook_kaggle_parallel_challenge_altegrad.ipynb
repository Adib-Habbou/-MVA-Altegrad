{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Installation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torch torch-geometric torch-scatter transformers pandas numpy"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import os.path as osp\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset as TorchDataset\n","from torch.utils.data import DataLoader as TorchDataLoader\n","\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.data import Dataset, Data\n","from torch_geometric.nn import GCNConv, GATConv, GATv2Conv, SuperGATConv\n","from torch_geometric.nn import global_mean_pool, global_max_pool\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","from torch_scatter import scatter_mean, scatter_max, scatter_add\n","\n","from transformers import AutoModel, AutoTokenizer, BertTokenizer, MegatronBertForMaskedLM, AutoModelForMaskedLM, T5EncoderModel, T5Tokenizer\n","\n","from sklearn.metrics.pairwise import cosine_similarity\n","from scipy.spatial.distance import euclidean, cityblock, jaccard, minkowski"]},{"cell_type":"markdown","metadata":{},"source":["## Data Sets/Loaders"]},{"cell_type":"markdown","metadata":{},"source":["### Graph-Text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class GraphTextDataset(Dataset):\n","    def __init__(self, root, gt, split, tokenizer=None, transform=None, pre_transform=None):\n","        self.root = root\n","        self.gt = gt\n","        self.split = split\n","        self.tokenizer = tokenizer\n","        self.description = pd.read_csv(os.path.join(self.root, split+'.tsv'), sep='\\t', header=None)\n","        self.description = self.description.set_index(0).to_dict()\n","        self.cids = list(self.description[1].keys())\n","\n","        self.idx_to_cid = {}\n","        i = 0\n","        for cid in self.cids:\n","            self.idx_to_cid[i] = cid\n","            i += 1\n","        super(GraphTextDataset, self).__init__(root, transform, pre_transform)\n","\n","    @property\n","    def raw_file_names(self):\n","        return [str(cid) + \".graph\" for cid in self.cids]\n","\n","    @property\n","    def processed_file_names(self):\n","        return ['data_{}.pt'.format(cid) for cid in self.cids]\n","\n","    @property\n","    def raw_dir(self) -> str:\n","        return osp.join(self.root, 'raw')\n","\n","    @property\n","    def processed_dir(self) -> str:\n","        return osp.join(self.root, 'processed/', self.split)\n","\n","    def download(self):\n","        pass\n","\n","    def process_graph(self, raw_path):\n","      edge_index  = []\n","      x = []\n","      with open(raw_path, 'r') as f:\n","        next(f)\n","        for line in f:\n","          if line != \"\\n\":\n","            edge = *map(int, line.split()),\n","            edge_index.append(edge)\n","          else:\n","            break\n","        next(f)\n","        for line in f: #get mol2vec features:\n","          substruct_id = line.strip().split()[-1]\n","          if substruct_id in self.gt.keys():\n","            x.append(self.gt[substruct_id])\n","          else:\n","            x.append(self.gt['UNK'])\n","        return torch.LongTensor(edge_index).T, torch.FloatTensor(x)\n","\n","    def process(self):\n","        i = 0\n","        for raw_path in self.raw_paths:\n","            cid = int(raw_path.split('\\\\')[-1][:-6])\n","            text_input = self.tokenizer([self.description[1][cid]],\n","                                   return_tensors=\"pt\",\n","                                   truncation=True,\n","                                   max_length=256,\n","                                   padding=\"max_length\",\n","                                   add_special_tokens=True,)\n","            edge_index, x = self.process_graph(raw_path)\n","            data = Data(x=x, edge_index=edge_index, input_ids=text_input['input_ids'], attention_mask=text_input['attention_mask'])\n","\n","            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n","            i += 1\n","\n","    def len(self):\n","        return len(self.processed_file_names)\n","\n","    def get(self, idx):\n","        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(self.idx_to_cid[idx])))\n","        return data\n","\n","    def get_cid(self, cid):\n","        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n","        return data"]},{"cell_type":"markdown","metadata":{},"source":["### Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whIWv_REn_2O","trusted":true},"outputs":[],"source":["class GraphDataset(Dataset):\n","    def __init__(self, root, gt, split, transform=None, pre_transform=None):\n","        self.root = root\n","        self.gt = gt\n","        self.split = split\n","        self.description = pd.read_csv(os.path.join(self.root, split+'.txt'), sep='\\t', header=None)\n","        self.cids = self.description[0].tolist()\n","\n","        self.idx_to_cid = {}\n","        i = 0\n","        for cid in self.cids:\n","            self.idx_to_cid[i] = cid\n","            i += 1\n","        super(GraphDataset, self).__init__(root, transform, pre_transform)\n","\n","    @property\n","    def raw_file_names(self):\n","        return [str(cid) + \".graph\" for cid in self.cids]\n","\n","    @property\n","    def processed_file_names(self):\n","        return ['data_{}.pt'.format(cid) for cid in self.cids]\n","\n","    @property\n","    def raw_dir(self) -> str:\n","        return osp.join(self.root, 'raw')\n","\n","    @property\n","    def processed_dir(self) -> str:\n","        return osp.join(self.root, 'processed/', self.split)\n","\n","    def download(self):\n","        pass\n","\n","    def process_graph(self, raw_path):\n","      edge_index  = []\n","      x = []\n","      with open(raw_path, 'r') as f:\n","        next(f)\n","        for line in f:\n","          if line != \"\\n\":\n","            edge = *map(int, line.split()),\n","            edge_index.append(edge)\n","          else:\n","            break\n","        next(f)\n","        for line in f:\n","          substruct_id = line.strip().split()[-1]\n","          if substruct_id in self.gt.keys():\n","            x.append(self.gt[substruct_id])\n","          else:\n","            x.append(self.gt['UNK'])\n","        return torch.LongTensor(edge_index).T, torch.FloatTensor(x)\n","\n","    def process(self):\n","        os.makedirs(self.processed_dir, exist_ok=True)\n","        i = 0\n","        for raw_path in self.raw_paths:\n","            cid = int(raw_path.split('\\\\')[-1][:-6])\n","            edge_index, x = self.process_graph(raw_path)\n","            data = Data(x=x, edge_index=edge_index)\n","            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n","            i += 1\n","\n","    def len(self):\n","        return len(self.processed_file_names)\n","\n","    def get(self, idx):\n","        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(self.idx_to_cid[idx])))\n","        return data\n","\n","    def get_cid(self, cid):\n","        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(cid)))\n","        return data\n","\n","    def get_idx_to_cid(self):\n","        return self.idx_to_cid"]},{"cell_type":"markdown","metadata":{},"source":["### Text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class TextDataset(TorchDataset):\n","    def __init__(self, file_path, tokenizer, max_length=256):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.sentences = self.load_sentences(file_path)\n","\n","    def load_sentences(self, file_path):\n","        with open(file_path, 'r', encoding='utf-8') as file:\n","            lines = file.readlines()\n","        return [line.strip() for line in lines]\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        sentence = self.sentences[idx]\n","\n","        encoding = self.tokenizer.encode_plus(\n","            sentence,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].squeeze(),\n","            'attention_mask': encoding['attention_mask'].squeeze()\n","        }"]},{"cell_type":"markdown","metadata":{},"source":["## Models"]},{"cell_type":"markdown","metadata":{},"source":["### Graph Encoder Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class GraphEncoderBaseline(nn.Module):\n","    def __init__(self, num_node_features, nout, nhid, graph_hidden_channels):\n","        super(GraphEncoderBaseline, self).__init__()\n","        self.nhid = nhid\n","        self.nout = nout\n","        self.relu = nn.ReLU()\n","        self.ln = nn.LayerNorm((nout))\n","        self.conv1 = GCNConv(num_node_features, graph_hidden_channels)\n","        self.conv2 = GCNConv(graph_hidden_channels, graph_hidden_channels)\n","        self.conv3 = GCNConv(graph_hidden_channels, graph_hidden_channels)\n","        self.mol_hidden1 = nn.Linear(graph_hidden_channels, nhid)\n","        self.mol_hidden2 = nn.Linear(nhid, nout)\n","\n","    def forward(self, graph_batch):\n","        x = graph_batch.x\n","        edge_index = graph_batch.edge_index\n","        batch = graph_batch.batch\n","        x = self.conv1(x, edge_index)\n","        x = x.relu()\n","        x = self.conv2(x, edge_index)\n","        x = x.relu()\n","        x = self.conv3(x, edge_index)\n","        x = global_mean_pool(x, batch)\n","        x = self.mol_hidden1(x).relu()\n","        x = self.mol_hidden2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class GraphEncoderAttention(nn.Module):\n","    def __init__(self, num_node_features, nout, nhid, graph_hidden_channels, num_heads=25, dropout=0.1):\n","        super(GraphEncoderAttention, self).__init__()\n","        self.nhid = nhid\n","        self.nout = nout\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout) \n","        self.conv1 = GATConv(num_node_features, graph_hidden_channels, heads=num_heads)\n","        self.conv2 = GATConv(graph_hidden_channels * num_heads, graph_hidden_channels, heads=num_heads)\n","        self.conv3 = GATConv(graph_hidden_channels * num_heads, graph_hidden_channels, heads=num_heads)\n","        self.mol_hidden1 = nn.Linear(graph_hidden_channels * num_heads, nhid)\n","        self.mol_hidden2 = nn.Linear(nhid, nout)\n","\n","    def forward(self, graph_batch):\n","        x = graph_batch.x\n","        edge_index = graph_batch.edge_index\n","        batch = graph_batch.batch\n","        x = self.conv1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = self.relu(x)\n","        x = self.conv3(x, edge_index)\n","        x, _ = scatter_max(x, batch, dim=0)\n","        x = self.mol_hidden1(x)\n","        x = self.mol_hidden2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class GraphEncoderAttentionV2(nn.Module):\n","    def __init__(self, num_node_features, nout, nhid, graph_hidden_channels, num_heads=25, dropout=0.1):\n","        super(GraphEncoderAttentionV2, self).__init__()\n","        self.nhid = nhid\n","        self.nout = nout\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout) \n","        self.conv1 = GATv2Conv(num_node_features, graph_hidden_channels, heads=num_heads)\n","        self.conv2 = GATv2Conv(graph_hidden_channels * num_heads, graph_hidden_channels, heads=num_heads)\n","        self.conv3 = GATv2Conv(graph_hidden_channels * num_heads, graph_hidden_channels, heads=num_heads)\n","        self.mol_hidden1 = nn.Linear(graph_hidden_channels * num_heads, nhid)\n","        self.mol_hidden2 = nn.Linear(nhid, nout)\n","\n","    def forward(self, graph_batch):\n","        x = graph_batch.x\n","        edge_index = graph_batch.edge_index\n","        batch = graph_batch.batch\n","        x = self.conv1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = self.relu(x)\n","        x = self.conv3(x, edge_index)\n","        x, _ = scatter_max(x, batch, dim=0)\n","        x = self.mol_hidden1(x)\n","        x = self.mol_hidden2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class GraphEncoderSuperAttention(nn.Module):\n","    def __init__(self, num_node_features, nout, nhid, graph_hidden_channels, num_heads=25, dropout=0.1):\n","        super(GraphEncoderSuperAttention, self).__init__()\n","        self.nhid = nhid\n","        self.nout = nout\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout) \n","        self.conv1 = SuperGATConv(num_node_features, graph_hidden_channels, heads=num_heads)\n","        self.conv2 = SuperGATConv(graph_hidden_channels * num_heads, graph_hidden_channels, heads=num_heads)\n","        self.conv3 = SuperGATConv(graph_hidden_channels * num_heads, graph_hidden_channels, heads=num_heads)\n","        self.mol_hidden1 = nn.Linear(graph_hidden_channels * num_heads, nhid)\n","        self.mol_hidden2 = nn.Linear(nhid, nout)\n","\n","    def forward(self, graph_batch):\n","        x = graph_batch.x\n","        edge_index = graph_batch.edge_index\n","        batch = graph_batch.batch\n","        x = self.conv1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.conv2(x, edge_index)\n","        x = self.relu(x)\n","        x = self.conv3(x, edge_index)\n","        x, _ = scatter_max(x, batch, dim=0)\n","        x = self.mol_hidden1(x)\n","        x = self.mol_hidden2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["### Text Encoder Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class TextEncoderBaseline(nn.Module):\n","    def __init__(self, model_name):\n","        super(TextEncoderBaseline, self).__init__()\n","        self.bert = AutoModel.from_pretrained(model_name)\n","\n","    def forward(self, input_ids, attention_mask):\n","        encoded_text = self.bert(input_ids, attention_mask=attention_mask)\n","        return encoded_text.last_hidden_state[:,0,:]"]},{"cell_type":"markdown","metadata":{},"source":["### Full Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, model_name, num_node_features, nout, nhid, graph_hidden_channels):\n","        super(Model, self).__init__()\n","        #self.graph_encoder = GraphEncoderAttention(num_node_features, nout, nhid, graph_hidden_channels)\n","        #self.graph_encoder = GraphEncoderAttentionV2(num_node_features, nout, nhid, graph_hidden_channels)\n","        self.graph_encoder = GraphEncoderSuperAttention(num_node_features, nout, nhid, graph_hidden_channels)\n","        self.text_encoder = TextEncoderBaseline(model_name)\n","        self.graph_encoder.to(\"cuda:0\")\n","        self.text_encoder.to(\"cuda:1\")\n","        \n","    def forward(self, graph_batch, input_ids, attention_mask):\n","        graph_batch = graph_batch.to(\"cuda:0\")\n","        graph_encoded = self.graph_encoder(graph_batch)\n","        input_ids = input_ids.to(\"cuda:1\")\n","        attention_mask = attention_mask.to(\"cuda:1\")\n","        text_encoded = self.text_encoder(input_ids, attention_mask)\n","        return graph_encoded, text_encoded\n","\n","    def get_text_encoder(self):\n","        return self.text_encoder\n","\n","    def get_graph_encoder(self):\n","        return self.graph_encoder"]},{"cell_type":"markdown","metadata":{},"source":["## Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["### Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device1 = torch.device(\"cuda:0\")\n","device2 = torch.device(\"cuda:1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["CE = torch.nn.CrossEntropyLoss()\n","\n","def contrastive_loss(v1, v2):\n","    logits = torch.matmul(v1,torch.transpose(v2, 0, 1))\n","    labels = torch.arange(logits.shape[0], device=v1.device)\n","    return CE(logits, labels) + CE(torch.transpose(logits, 0, 1), labels)"]},{"cell_type":"markdown","metadata":{},"source":["### Text Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_name = \"distilbert-base-uncased\"\n","#model_name = \"allenai/scibert_scivocab_uncased\"\n","#model_name = \"monologg/biobert_v1.1_pubmed\"\n","#model_name = \"nv/biomegatron345m\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","gt = np.load(\"/kaggle/input/data/token_embedding_dict.npy\", allow_pickle=True)[()]\n","val_dataset = GraphTextDataset(root='/kaggle/input/data', gt=gt, split='val', tokenizer=tokenizer)\n","train_dataset = GraphTextDataset(root='/kaggle/input/data', gt=gt, split='train', tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["### Train and Validation Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_part1 = GraphEncoderAttention(num_node_features=300, nout=768, nhid=768, graph_hidden_channels=500).to(device1)\n","model_part2 = TextEncoderBaseline(model_name).to(device2)\n","\n","nb_epochs = 30\n","batch_size = 32\n","learning_rate = 1e-5\n","\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","\n","optimizer = optim.AdamW(list(model_part1.parameters())+list(model_part2.parameters()), lr=learning_rate, betas=(0.9, 0.999), weight_decay=0.01)\n","scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0)\n","\n","epoch = 0\n","loss = 0\n","losses = []\n","count_iter = 0\n","time1 = time.time()\n","printEvery = 50\n","best_validation_loss = 1000000\n","best_lrap_score = 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#model_path = '/kaggle/input/model-best/model_best.pt'\n","#checkpoint = torch.load(model_path)\n","\n","#model_part1.load_state_dict(checkpoint['model_state_dict1'])\n","#model_part2.load_state_dict(checkpoint['model_state_dict2'])\n","\n","#optimizer = optim.AdamW(list(model_part1.parameters())+list(model_part2.parameters()), lr=learning_rate, betas=(0.9, 0.999), weight_decay=0.01)\n","#optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0)\n","#scheduler = checkpoint['scheduler']\n","#start_epoch = checkpoint['epoch']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in range(nb_epochs):\n","    print('------------------------- EPOCH {} -------------------------'.format(i+1))\n","    model_part1.train()\n","    model_part2.train()\n","    \n","    for batch in train_loader:\n","        input_ids = batch.input_ids\n","        batch.pop('input_ids')\n","        attention_mask = batch.attention_mask\n","        batch.pop('attention_mask')\n","        graph_batch = batch\n","\n","        x_graph = model_part1(graph_batch.to(device1))\n","        x_text = model_part2(input_ids.to(device2),\n","                            attention_mask.to(device2))\n","        \n","        x_text = x_text.to(device2)\n","        x_graph = x_graph.to(device2)\n","        current_loss = contrastive_loss(x_graph, x_text)\n","        optimizer.zero_grad()\n","        current_loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        loss += current_loss.item()\n","\n","        count_iter += 1\n","        if count_iter % printEvery == 0:\n","            time2 = time.time()\n","            print(\"Iteration: {0}, Time: {1:.4f} s, Training Loss: {2:.4f}\".format(count_iter, time2 - time1, loss/printEvery))\n","            losses.append(loss)\n","            loss = 0\n","            \n","    model_part1.eval()\n","    model_part2.eval()\n","    val_loss = 0\n","\n","    for batch in val_loader:\n","        input_ids = batch.input_ids\n","        batch.pop('input_ids')\n","        attention_mask = batch.attention_mask\n","        batch.pop('attention_mask')\n","        graph_batch = batch\n","        x_graph = model_part1(graph_batch.to(device1))\n","        x_text = model_part2(input_ids.to(device2), attention_mask.to(device2))\n","        x_text = x_text.to(device2)\n","        x_graph = x_graph.to(device2)\n","\n","        current_loss = contrastive_loss(x_graph, x_text)\n","        val_loss += current_loss.item()\n","\n","    best_validation_loss = min(best_validation_loss, val_loss)\n","\n","    print('\\nEpoch ' + str(i+1) + ' done.  Validation Loss: ', str(val_loss/len(val_loader)) )\n","\n","    if best_validation_loss==val_loss:\n","        print('Validation Loss Improoved')\n","        print('Saving Checkpoint...')\n","        save_path = os.path.join('./', 'model_best.pt')\n","        torch.save({\n","            'epoch': i,\n","            'model_state_dict1': model_part1.state_dict(),\n","            'model_state_dict2': model_part2.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scheduler': scheduler,\n","            'validation_accuracy': val_loss,\n","            'loss': loss,\n","            }, save_path)\n","        print('Checkpoint Saved To: {}\\n'.format(save_path))\n","    else:\n","        print('Validation Loss Not Improoved\\n')"]},{"cell_type":"markdown","metadata":{},"source":["### Best Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print('Loading Best Model...\\n')\n","  \n","checkpoint = torch.load(save_path)\n","model_part1.load_state_dict(checkpoint['model_state_dict1'])\n","model_part2.load_state_dict(checkpoint['model_state_dict2'])\n","model_part1.eval()\n","model_part2.eval()\n","\n","graph_model = model_part1\n","text_model = model_part2\n","\n","print('Loading Best Model Done!')"]},{"cell_type":"markdown","metadata":{},"source":["### Test Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print('Text Embeddings...\\n')\n","\n","test_cids_dataset = GraphDataset(root='/kaggle/input/data/', gt=gt, split='test_cids')\n","test_text_dataset = TextDataset(file_path='/kaggle/input/data/test_text.txt', tokenizer=tokenizer)\n","\n","idx_to_cid = test_cids_dataset.get_idx_to_cid()\n","\n","test_loader = DataLoader(test_cids_dataset, batch_size=batch_size, shuffle=False)\n","\n","graph_embeddings = []\n","for batch in test_loader:\n","    for output in graph_model(batch.to(device1)):\n","        graph_embeddings.append(output.tolist())\n","\n","test_text_loader = TorchDataLoader(test_text_dataset, batch_size=batch_size, shuffle=False)\n","text_embeddings = []\n","for batch in test_text_loader:\n","    for output in text_model(batch['input_ids'].to(device2),\n","                             attention_mask=batch['attention_mask'].to(device2)):\n","        text_embeddings.append(output.tolist())\n","        \n","print('Text Embeddings Done!')"]},{"cell_type":"markdown","metadata":{},"source":["### Sumbission File Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print('Creating Submission File...\\n')\n","\n","similarity = cosine_similarity(text_embeddings, graph_embeddings)\n","#similarity = euclidean(text_embeddings, graph_embeddings)\n","#similarity = minkowski(text_embeddings, graph_embeddings)\n","#similarity = jaccard(text_embeddings, graph_embeddings)\n","#similarity = cityblock(text_embeddings, graph_embeddings)\n","\n","solution = pd.DataFrame(similarity)\n","solution['ID'] = solution.index\n","solution = solution[['ID'] + [col for col in solution.columns if col!='ID']]\n","solution.to_csv('submission.csv', index=False)\n","\n","print('Submission File Ready!')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4224039,"sourceId":7284503,"sourceType":"datasetVersion"},{"datasetId":4229102,"sourceId":7291781,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
